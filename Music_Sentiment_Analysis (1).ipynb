{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac55599c",
   "metadata": {},
   "source": [
    "<h2>The required packages</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c7e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dab85b0",
   "metadata": {},
   "source": [
    "<h2>The data set</h2>\n",
    "<p>Since the dataset was too big, I only took like first few</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "916b4625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lines</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>dear rahul\\nwhat new minimum income scheme 720...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>promises times support poorest poor comparison...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>wah bhakt dont you know the difference between...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>well plz dont geberalise kolkata for bengal vi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>absolute judgement are humans there should not...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5119 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  lines  category\n",
       "0      family mormon have never tried explain them t...       1.0\n",
       "1     buddhism has very much lot compatible with chr...       1.0\n",
       "2     seriously don say thing first all they won get...      -1.0\n",
       "3     what you have learned yours and only yours wha...       0.0\n",
       "4     for your own benefit you may want read living ...       1.0\n",
       "...                                                 ...       ...\n",
       "5114  dear rahul\\nwhat new minimum income scheme 720...      -1.0\n",
       "5115  promises times support poorest poor comparison...      -1.0\n",
       "5116  wah bhakt dont you know the difference between...       0.0\n",
       "5117  well plz dont geberalise kolkata for bengal vi...       1.0\n",
       "5118  absolute judgement are humans there should not...       1.0\n",
       "\n",
       "[5119 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data = pd.read_csv('Reddit_Data.csv').head(1862) # 1862\n",
    "reddit_data = reddit_data.dropna()\n",
    "twitter_data = pd.read_csv('Twitter_Data.csv').head(3260) #3260\n",
    "twitter_data = twitter_data.dropna()\n",
    "df = pd.DataFrame(data=list(reddit_data['clean_comment']),columns=['lines'])\n",
    "df['category'] = list(reddit_data['category'])\n",
    "twitter_data = twitter_data.rename(columns={'clean_text': 'lines'})\n",
    "df = df.append(twitter_data,ignore_index=True)\n",
    "df.to_csv('final_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc59700c",
   "metadata": {},
   "source": [
    "<h2>Naive Bayes Classifier class</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6c0d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self,df):\n",
    "        self.words = []\n",
    "        self.lines = list(df['lines'])\n",
    "        self.sentiments = list(df['category'])\n",
    "    def word_extraction(self):\n",
    "        for line in self.lines:\n",
    "            if(type(line) is not str): # some comments were actually of float type instead of string so I put this if block here to convert them to string and then train them\n",
    "                i = self.lines.index(line)\n",
    "                line = str(line)\n",
    "                self.lines[i] = line\n",
    "            w = line.strip().split()\n",
    "            for x in w:\n",
    "                if(self.words.count(x) == 0):\n",
    "                    self.words.append(x)\n",
    "    def train_model(self): # training the model\n",
    "        self.word_extraction() # calling the word extractor function to extract words from the dataset\n",
    "        positive = [] # count of times when the particular word is being used for positive sentiment\n",
    "        negative = [] # count of times when the particular word is being used for negative sentiment\n",
    "        neutral = [] # count of times when the particular word is being used for neutral sentiment\n",
    "        total = [] # count of times the particular word is used in dataset\n",
    "        for i in range(0,len(self.words)):\n",
    "            positive.append(0)\n",
    "            negative.append(0)\n",
    "            neutral.append(0)\n",
    "            for j in range(0,len(self.lines)):\n",
    "                if(self.sentiments[j] == -1): # negative\n",
    "                    negative[i] += self.lines[j].count(self.words[i])\n",
    "                elif(self.sentiments[j] == 0): # neutral\n",
    "                    neutral[i] += self.lines[j].count(self.words[i])\n",
    "                elif(self.sentiments[j] == 1): # positive\n",
    "                    positive[i] += self.lines[j].count(self.words[i])\n",
    "            total.append(positive[i]+negative[i]+neutral[i])\n",
    "        positive.append(sum(positive)) # count of total comments with positive sentiments\n",
    "        neutral.append(sum(neutral)) # count of total comments with neutral sentiments\n",
    "        negative.append(sum(negative)) # count of total comments with negative sentiments\n",
    "        l = len(positive)\n",
    "        total.append(positive[l-1]+negative[l-1]+neutral[l-1]) # total comments we are training (it will be a fixed value so I don't know why I still did it, haha I don't know how to put emojis in comment, so understand the meotions here \"smile in pain\")\n",
    "        count = [negative, neutral, positive, total] # data for the lookup table data frame\n",
    "        self.make_lookup(count)\n",
    "        print('Model trained.')\n",
    "    def make_lookup(self,count): # for creating a loopup table data frame\n",
    "        col = copy.deepcopy(self.words)\n",
    "        self.V = len(self.words)\n",
    "        col.append('_TOTAL_')\n",
    "        self.lookup = pd.DataFrame(count,columns=col,index=['NEGATIVE','NEUTRAL','POSITIVE','TOTAL'])\n",
    "        self.lookup.to_csv('lookup-naive-bayes.csv')\n",
    "    def extract_keywords(self,doc): # to extract the required keywords from the input sentence (the words that are already present in our lookup table)\n",
    "        words = doc.strip().lower().split()\n",
    "        keywords = []\n",
    "        for i in range(0,len(words)):\n",
    "            if(type(words[i]) is not str):\n",
    "                words[i] = str(words[i])\n",
    "            if(self.words.count(words[i]) != 0):\n",
    "                keywords.append(words[i])\n",
    "        return keywords\n",
    "    def make_predictions(self,doc,alpha=0):\n",
    "        keywords = self.extract_keywords(doc)\n",
    "        #conditionProb = [1,1,1] # conditional probabilties\n",
    "        P = [self.sentiments.count(-1), self.sentiments.count(0), self.sentiments.count(1)] # prior probabilites\n",
    "        for i in range(0,3):\n",
    "            P[i] /= len(self.sentiments)\n",
    "        for k in keywords:\n",
    "            # for negative\n",
    "            P[0] *= (self.lookup[k][0] + alpha) / (self.lookup['_TOTAL_'][0] + (alpha*self.V))\n",
    "            # for neutral\n",
    "            P[1] *= (self.lookup[k][1] + alpha) / (self.lookup['_TOTAL_'][1] + (alpha*self.V))\n",
    "            # for positive\n",
    "            P[2] *= (self.lookup[k][2] + alpha) / (self.lookup['_TOTAL_'][2] + (alpha*self.V))\n",
    "        res = [P]\n",
    "        if(P[0] > P[1] and P[0] > P[2]):\n",
    "            res.append('Negative')\n",
    "        elif(P[1] > P[0] and P[1] > P[2]):\n",
    "            res.append('Neutral')\n",
    "        elif(P[2] > P[0] and P[2] > P[1]):\n",
    "            res.append('Positive')\n",
    "        else:\n",
    "            res.append('Unpredictable')\n",
    "        return res\n",
    "    def make_predictions_multiline(self,doc,alpha=0):\n",
    "        count = [0,0,0,0] # so it is like [ negative, neutral, positive, unpredictable]\n",
    "        res = []\n",
    "        X = doc.strip().split('\\n')\n",
    "        for x in X:\n",
    "            y = self.make_predictions(x,alpha)\n",
    "            # print(y[0],'\\t',y[1])\n",
    "            if(y[1] == 'Negative'):\n",
    "                count[0] += 1\n",
    "            elif(y[1] == 'Neutral'):\n",
    "                count[1] += 1\n",
    "            elif(y[1] == 'Positive'):\n",
    "                count[2] += 1\n",
    "            elif(y[1] == 'Unpredictable'):\n",
    "                count[3] += 1\n",
    "        self.print_percent(count)\n",
    "    def print_percent(self,count):\n",
    "        percent = []\n",
    "        for c in count:\n",
    "            percent.append((c*100)/sum(count))\n",
    "        print('Results:\\n')\n",
    "        if(percent[3] < 50.0):\n",
    "            print('Positive: ',percent[2])\n",
    "            print('Negative: ',percent[0])\n",
    "            print('Neutral: ',percent[1])\n",
    "        else:\n",
    "            print('Unpredictable: ',percent[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17d4818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained.\n",
      "Training time:  82.30496001243591\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "model = NaiveBayes(df)\n",
    "model.train_model()\n",
    "endTime = time.time()\n",
    "totalTime = endTime-startTime\n",
    "print('Training time: ',totalTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d855037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How long have you been smiling?\n",
      "It seems like it's been too long\n",
      "Some days I don't feel like trying\n",
      "So what the fuck are you on\n",
      "Whoa, ohh\n",
      "I think too much, we drink too much\n",
      "Falling in love like it's just nothing\n",
      "I want to know where do we go\n",
      "When nothing's wrong\n",
      "'Cause all the kids are depressed\n",
      "Nothing ever makes sense\n",
      "I'm not feeling alright\n",
      "Staying up 'til sunrise\n",
      "And hoping shit is okay\n",
      "Pretending we know things\n",
      "I don't know what happened\n",
      "My natural reaction is that we're scared\n",
      "Ohh-oh-oh\n",
      "Noo-oo-oo\n",
      "Ohh-oh-oh...\n",
      "So I guess we're scared\n",
      "Ohh-oh-oh, ohh-oh-oh\n"
     ]
    }
   ],
   "source": [
    "file = open('lyrics.txt','r')\n",
    "X = file.read()\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bbf2e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Alpha:  0\n",
      "Results:\n",
      "\n",
      "Positive:  81.81818181818181\n",
      "Negative:  13.636363636363637\n",
      "Neutral:  4.545454545454546\n",
      "\n",
      "\n",
      "Alpha:  1\n",
      "Results:\n",
      "\n",
      "Positive:  81.81818181818181\n",
      "Negative:  13.636363636363637\n",
      "Neutral:  4.545454545454546\n",
      "\n",
      "\n",
      "Alpha:  2\n",
      "Results:\n",
      "\n",
      "Positive:  86.36363636363636\n",
      "Negative:  9.090909090909092\n",
      "Neutral:  4.545454545454546\n",
      "\n",
      "\n",
      "Alpha:  3\n",
      "Results:\n",
      "\n",
      "Positive:  86.36363636363636\n",
      "Negative:  9.090909090909092\n",
      "Neutral:  4.545454545454546\n",
      "\n",
      "\n",
      "Alpha:  4\n",
      "Results:\n",
      "\n",
      "Positive:  90.9090909090909\n",
      "Negative:  4.545454545454546\n",
      "Neutral:  4.545454545454546\n",
      "\n",
      "\n",
      "Alpha:  5\n",
      "Results:\n",
      "\n",
      "Positive:  90.9090909090909\n",
      "Negative:  4.545454545454546\n",
      "Neutral:  4.545454545454546\n",
      "\n",
      "\n",
      "Alpha:  6\n",
      "Results:\n",
      "\n",
      "Positive:  90.9090909090909\n",
      "Negative:  4.545454545454546\n",
      "Neutral:  4.545454545454546\n",
      "\n",
      "\n",
      "Alpha:  7\n",
      "Results:\n",
      "\n",
      "Positive:  95.45454545454545\n",
      "Negative:  0.0\n",
      "Neutral:  4.545454545454546\n",
      "\n",
      "\n",
      "Alpha:  8\n",
      "Results:\n",
      "\n",
      "Positive:  95.45454545454545\n",
      "Negative:  0.0\n",
      "Neutral:  4.545454545454546\n",
      "\n",
      "\n",
      "Alpha:  9\n",
      "Results:\n",
      "\n",
      "Positive:  95.45454545454545\n",
      "Negative:  0.0\n",
      "Neutral:  4.545454545454546\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "for i in range(0,epoch):\n",
    "    print('\\n\\nAlpha: ',i)\n",
    "    model.make_predictions_multiline(X,alpha=i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
